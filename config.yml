{
    seed: 0,    

    # Network Hyperparameters
    hidden_dims: [32, 64, 64],
    learning_rate: 0.001,
    activation: relu, # relu or tanh

    # training
    batch_size: 32,
    buffer_size: 1000,
    num_warmup: 50,
    num_sample_last: 75,
    num_episodes_update: 10,
    num_steps_update: 200,
    horizon_scale: 0.02,
    return_scale: 0.02,
    max_episodes: 10000,

    eval_every: 100,
    eval_num_episodes: 100,

    # RL parameters
    env_name: LunarLander-v2,

    #Logging and saving
    log_file: TestNet,
    save_updates: 100,

    use_cuda: True,
}
