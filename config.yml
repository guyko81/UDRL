{
    # Network Hyperparameters
    hidden_dims: [32, 64, 64],
    learning_rate: 0.001,
    activation: relu, # relu or tanh

    # training
    batch_size: 32,
    buffer_size: 1000,
    num_warmup: 50,
    num_sample_last: 75,
    num_episodes_update: 10,
    num_steps_update: 200,
    horizon_scale: 0.02,
    return_scale: 0.02,
    max_episodes: 10000,

    # RL parameters
    env_name: LunarLander-v2,

    #Logging and saving
    log_file: TestNet,
    save_updates: 100,
}
